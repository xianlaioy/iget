<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.0.9 (458233)"/><meta name="created" content="2018-04-16 02:59:00 +0000"/><meta name="updated" content="2018-04-17 11:53:04 +0000"/><title>李翔知识内参｜方法：如何避免灾难性失败</title></head><body><div>方法：如何避免灾难性失败</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">很多重大失败通过事后的分析总结，人们能够得出教训，下一次避免同样的问题再度发生。但是，这种<b>事后总结的方法却越来越难以应对一些复杂系统产生的新问题了</b>。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">前金融衍生品交易员克里斯·克利尔菲尔德（Chris Clearfield）和多伦多大学教授安德拉什·蒂尔奇克（András Tilcsik&nbsp;&nbsp;）在研究了很多灾难性失败的案例之后，合作出版了一本新书<b>《崩溃：为什么我们的系统会失败和我们对此能做些什么》</b>（Meltdown: Why Our Systems Fail and What We Can Do About It）。他们得出了一个结论：<b>随着系统变得越来越复杂，在人工智能和算法以及人类经验的影响下，系统反而更容易出现灾难性失败</b>，结果就是我们现在处于“崩溃的黄金时代”。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">克里斯与安德拉什他们的研究最初开始于一个意外事件——三里岛核泄漏事故。1979年，美国宾夕法尼亚州三里岛核电站的一个机组因为事故导致反应堆瘫痪。在事故发生后，当地政府紧急疏散了周边地区20万居民，幸好最后没有任何伤亡，对环境也几乎没有影响。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">在这次事故之后，社会学家查尔斯·佩罗开始对复杂的技术系统中简单的人为错误导致的失控产生了兴趣。这位社会学家研究后发现，三里岛核泄漏事故不是由地震或恐怖袭击等大规模外部冲击造成的，而是由包括管道故障、维护人员疏忽、阀门被卡住、控制室内指示器混乱等小故障的交互叠加造成的。作为历史上最严重的核事故之一，三里岛核泄漏事故实际上是以一种奇特的方式聚集起了一些小事故而造成了大事故。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">这样的“崩溃”源自于两个变量，第一个变量是<b>复杂性</b>。如果<b>系统越复杂，其各个部分越容易相互影响</b>；系统越复杂，导致我们<b>越需要依靠间接的指标来评估问题</b>。比如在核电站，我们就不能直接派人去看核反应堆发生了什么问题，而需要压力、水流量等间接指标来拼凑出一个反应堆的完整情况。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">第二个变量是<b>耦合性</b>。耦合性是一个工程术语，就是说当<b>系统紧密耦合时，各个部分之间几乎没有缓冲区，对误差的容忍度很小</b>。这就意味着<b>一部分的故障很容易影响整个系统的其他部分</b>，而我们又不能为处理某个部分的问题而关闭整个系统。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">因此，<b>复杂性和紧密耦合的结合，会把系统推到危险区域</b>。在<b>复杂的系统中，小错误是不可避免的</b>，而复杂的系统也会产生让人困惑的症状，因为这些我们可能<b>很难做出正确的诊断</b>，甚至可能解决了错误的问题而让事情变得更加糟糕了。如果系统同时也是紧密耦合的，我们就无法阻止倒塌的“多米诺骨牌”了。<b>小错误会迅速蔓延并失去控制</b>，最终导致灾难性失败的发生。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">三里岛核泄漏事故之后，世界的复杂性和紧密耦合性在趋势上都是大大增加的，直接导致危险区域也随之增多了。在这种趋势下，如果我们无法改变系统，那就要搞清楚如何管理复杂系统。对此，克利尔菲尔德和蒂尔奇克这两位作者就提出了在复杂系统中有助于减少灾难性失败的策略：</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">第一步是在意识层面，<b>要认识到世界已经发生了变化</b>，这是一件很难的事。我们要意识到，我们正面临一种不同的挑战，<b>灾难性失败不是来自外部冲击，而是来自技术故障和人类错误的组合。</b></div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">2012年，华尔街巨头骑士资本无意中交易了数十亿美元的股票，并在短短半小时内损失了近5亿美元，原因仅仅是软件故障，在十年前是不可能发生这样让人震惊的“崩溃”。然而，几年过去了，骑士资本的时任CEO在接受采访时依然认为，骑士资本不是技术公司，而是使用技术的经纪公司。这显示出，他依然把技术看作支持功能，而不是核心功能。可见要改变已有的认知是多么难。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">现在，我们需要从复杂性和紧密耦合的角度来评估项目或业务。如果我们在危险区域运营，就必须尝试<b>简化系统、增加透明度或为系统引入更多的“松懈度”，让系统不要那么紧密耦合。</b></div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">第二步是在<b>工具和方法层面</b>，可以<b>引入行为经济学的工具</b>，比如可以采用“<b>事前验尸”的方法</b>，就是通过<b>预设失败，想象项目失败并找出原因</b>，<b>以求成功</b>。“事后验尸”是事后的检讨，“复盘”的意义很大，但对于已经“崩溃”的公司而言，没有什么帮助。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">比如说，对于一支攀登珠穆朗玛峰的远征队，这座山是一个复杂而紧密的系统，对此我们无能为力，但仍然可以采取措施让攀登珠穆朗玛峰更安全。如果我们想象一下登顶失败的原因，就会发现可能是出于航班延误、海关问题、物品供应问题和消化疾病等小问题而造成最终的失败。因此，我们就可以意识到，真正的杀手不是山，而是许多小问题的相互作用，我们也能够想到一个解决方案：尽可能多地解决后勤问题。正如一家公司的宣传册所说：“我们对珠穆朗玛峰和世界各地高山的食物及其准备工作的关注，让我们团队成员的肠胃问题极少。”</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">第三步<b>，摒弃群体思维，鼓励不同意见</b>。麻省理工学院的研究表明，人们倾向于和自己所熟悉的团队达成一致，当团队中的成员来源多样化后，人们发表意见的可能性大为增加。美国宇航局的喷气推进实验室负责世界上最复杂的工程工作。在经历了一些失败的项目之后，该实验室开始使用外部人员来帮助他们管理任务风险。现在该实验室还创建了工程技术局（ETA），给每个项目配备一名ETA工程师，从而让项目团队成员来源更加多样。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">此外，<b>组织还要不断引入“陌生人”的冲击</b>，这些“陌生人”<b>既要对组织有所了解，具备“相关性”，同时还要和组织有一定距离，从而能够从不同角度看待问题</b>。比如制药巨头诺和诺德公司在质量控制危机后，意识到该公司的制造系统过于复杂，无法使用传统方式进行管理。该公司随后创建了一个约二十人的部门，负责扫描管理人员面临的新挑战。这些人的工作就是四处走走，发现并跟进一些小问题。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">以上就是我们现在应对复杂系统，避免出现灾难性失败的方法，希望对你有启发。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">本文参考来源：《崩溃：为什么我们的系统会失败和我们对此能做些什么》（Meltdown: Why Our Systems Fail and What We Can Do About It）；作者：克里斯·克利尔菲尔德（Chris Clearfield）、安德拉什·蒂尔奇克（András Tilcsik&nbsp;&nbsp;）。</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">改写：唐帅</div><div style="margin-top: 1em; margin-bottom: 1em;-en-paragraph:true;">讲述：顾一菲</div><div>用户留言 写留言 提交留言可与专栏作者互动</div></body></html>